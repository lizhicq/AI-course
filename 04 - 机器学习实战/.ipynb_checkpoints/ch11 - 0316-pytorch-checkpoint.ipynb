{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image', cmap='binary')\n",
    "for i in range(10):# print 10 image\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model1()\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = m.fit(train_x, train_y, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1), test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor()\n",
    "#   ,transforms.Normalize((),())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Normoalize\n",
    "object : 将图片进行归一化缩放（X-mean)/std\n",
    "\n",
    "思考：图片归一化后，真的不存在小于0或者大于1的outlier了吗？\n",
    "\n",
    "思考：归一化后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1307003"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30815956"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.1307),(.3081))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.MNIST('data',train=True,download=True,transform=data_trans)\n",
    "test_data=datasets.MNIST('data',train=False,download=True,transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_data)*0.9)\n",
    "n_validation = len(train_data) - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)\n",
    "test_iterator = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        #第一层conv1卷积层， in_channel=1, output_channel=6, kernel_size = 5*5\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 80)\n",
    "        self.fc3 = nn.Linear(80, 10) # 不用加softmax层，在corss_entropy的Loss层中自动增加了Softmax\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到此神经网络定义完毕"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何评测结果--计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx, y):\n",
    "    pred = fx.max(1, keepdim=True)[1]\n",
    "    correct = pred.eq(y.view_as(pred)).sum()\n",
    "    acc = correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0#积累变量\n",
    "    epoch_acc=0#积累变量\n",
    "    model.train()#该函数表示PHASE=Train\n",
    "    \n",
    "    for (x,y) in iterator:#拿去每一个minibatch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        fx=model(x)#进行forward\n",
    "        loss=criterion(fx,y)#计算Loss,train_loss\n",
    "        type(loss)\n",
    "        acc=accu(fx,y)#计算精确度，train_accu\n",
    "        loss.backward()#进行BP\n",
    "        optimizer.step()#统一更新模型\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_dir='models'\n",
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.27957420936075006|Train Acc:0.9136305292494489|Val Loss:0.11500227784222745|Val Acc:0.9648160465220188\n",
      "Epoch:2|Train Loss:0.07811058227687863|Train Acc:0.9749950632382344|Val Loss:0.06998286420043479|Val Acc:0.9789450358837208\n",
      "Epoch:3|Train Loss:0.05393652880114119|Train Acc:0.9834431773537143|Val Loss:0.05595155837053948|Val Acc:0.9833776595744681\n",
      "Epoch:4|Train Loss:0.04243401201360228|Train Acc:0.9864484597156398|Val Loss:0.06212549500088108|Val Acc:0.981216755319149\n",
      "Epoch:5|Train Loss:0.03428043748397751|Train Acc:0.9892007306712498|Val Loss:0.054498820526010176|Val Acc:0.9832114361702128\n",
      "Epoch:6|Train Loss:0.028806797855520417|Train Acc:0.99103352095561|Val Loss:0.05036632982181742|Val Acc:0.9844304082241464\n",
      "Epoch:7|Train Loss:0.02527874791100886|Train Acc:0.9915025177725119|Val Loss:0.036658450317113324|Val Acc:0.9883643617021277\n",
      "Epoch:8|Train Loss:0.021336429714339994|Train Acc:0.9929835604265402|Val Loss:0.04410999297025673|Val Acc:0.9863696808510638\n",
      "Epoch:9|Train Loss:0.018676721795475314|Train Acc:0.9940141192968422|Val Loss:0.049389642108469564|Val Acc:0.9845412234042553\n",
      "Epoch:10|Train Loss:0.016199574346065972|Train Acc:0.9943535248815166|Val Loss:0.04749543186118628|Val Acc:0.9865359042553191\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
