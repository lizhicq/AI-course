{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def reduce_dimen(dataset,column,toreplace):\n",
    "    for index,i in dataset[column].duplicated(keep=False).iteritems():\n",
    "        if i==False:\n",
    "            dataset.set_value(index,column,toreplace)\n",
    "    return dataset\n",
    "    \n",
    "def act_data_treatment(dsname):\n",
    "    dataset = dsname\n",
    "    \n",
    "    for col in list(dataset.columns):\n",
    "        if col not in ['people_id', 'activity_id', 'date', 'char_38', 'outcome']:\n",
    "            if dataset[col].dtype == 'object':\n",
    "                dataset[col].fillna('type 0', inplace=True)\n",
    "                dataset[col] = dataset[col].apply(lambda x: x.split(' ')[1]).astype(np.int32)\n",
    "            elif dataset[col].dtype == 'bool':\n",
    "                dataset[col] = dataset[col].astype(np.int8)\n",
    "    \n",
    "    dataset['year'] = dataset['date'].dt.year\n",
    "    dataset['month'] = dataset['date'].dt.month\n",
    "    dataset['day'] = dataset['date'].dt.day\n",
    "    dataset['isweekend'] = (dataset['date'].dt.weekday >= 5).astype(int)\n",
    "    dataset = dataset.drop('date', axis = 1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "act_train_data = pd.read_csv(\"input/act_train.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "act_test_data  = pd.read_csv(\"input/act_test.csv\", dtype={'people_id': np.str, 'activity_id': np.str}, parse_dates=['date'])\n",
    "people_data    = pd.read_csv(\"input/people.csv\", dtype={'people_id': np.str, 'activity_id': np.str, 'char_38': np.int32}, parse_dates=['date'])\n",
    "\n",
    "act_train_data=act_train_data.drop('char_10',axis=1)\n",
    "act_test_data=act_test_data.drop('char_10',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (2197291, 14)\n",
      "Test data shape: (498687, 13)\n",
      "People data shape: (189118, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: \" + format(act_train_data.shape))\n",
    "print(\"Test data shape: \" + format(act_test_data.shape))\n",
    "print(\"People data shape: \" + format(people_data.shape))\n",
    "\n",
    "act_train_data  = act_data_treatment(act_train_data)\n",
    "act_test_data   = act_data_treatment(act_test_data)\n",
    "people_data = act_data_treatment(people_data)\n",
    "\n",
    "train = act_train_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "test  = act_test_data.merge(people_data, on='people_id', how='left', left_index=True)\n",
    "\n",
    "del act_train_data\n",
    "del act_test_data\n",
    "del people_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lizhi\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train=train.sort_values(['people_id'], ascending=[1])\n",
    "test=test.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "train_columns = train.columns.values\n",
    "test_columns = test.columns.values\n",
    "features = list(set(train_columns) & set(test_columns))\n",
    "\n",
    "train.fillna('NA', inplace=True)\n",
    "test.fillna('NA', inplace=True)\n",
    "\n",
    "y = train.outcome\n",
    "train=train.drop('outcome',axis=1)\n",
    "\n",
    "whole=pd.concat([train,test],ignore_index=True)\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "for category in categorical:\n",
    "    whole=reduce_dimen(whole,category,9999999)\n",
    "\n",
    "Len = int(0.3*len(train))\n",
    "X_train=whole[:Len]\n",
    "Y_train=y[:Len]\n",
    "X=whole[:len(train)]\n",
    "Y=y[:len(train)]\n",
    "X_test=whole[len(train):]\n",
    "\n",
    "del train\n",
    "del whole\n",
    "    \n",
    "X=X.sort_values(['people_id'], ascending=[1])\n",
    "X_train = X_train.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "X_train = X_train[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "X = X[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "X_test = X_test[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "\n",
    "categorical=['group_1','activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x','char_6_x','char_7_x','char_8_x','char_9_x','char_2_y','char_3_y','char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']\n",
    "not_categorical=[]\n",
    "for category in X.columns:\n",
    "    if category not in categorical:\n",
    "        not_categorical.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# enc=enc.fit(pd.concat([X[categorical],X_test[categorical]]))\n",
    "# X_cat_sparse=enc.transform(X[categorical])\n",
    "# X_test_cat_sparse=enc.transform(X_test[categorical])\n",
    "\n",
    "# from scipy.sparse import hstack\n",
    "# X_sparse=hstack((X[not_categorical], X_cat_sparse))\n",
    "# X_test_sparse=hstack((X_test[not_categorical], X_test_cat_sparse))\n",
    "\n",
    "# print(\"Training data: \" + format(X_sparse.shape))\n",
    "# print(\"Test data: \" + format(X_test_sparse.shape))\n",
    "# print(\"###########\")\n",
    "# print(\"One Hot enconded Test Dataset Script\")\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_sparse,label=y)\n",
    "# dtest = xgb.DMatrix(X_test_sparse)\n",
    "\n",
    "# param = {'max_depth':10, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\n",
    "# param['nthread'] = 4\n",
    "# param['eval_metric'] = 'auc'\n",
    "# param['subsample'] = 0.7\n",
    "# param['colsample_bytree']= 0.7\n",
    "# param['min_child_weight'] = 0\n",
    "# param['booster'] = \"gblinear\"\n",
    "\n",
    "# watchlist  = [(dtrain,'train')]\n",
    "# num_round = 300\n",
    "# early_stopping_rounds=10\n",
    "# bst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost params. ETA: 0.9, MAX_DEPTH: 5, SUBSAMPLE: 0.8, COLSAMPLE_BY_TREE: 0.8\n",
      "[0]\ttrain-auc:0.914123\tval-auc:0.912273\n",
      "Multiple eval metrics have been passed: 'val-auc' will be used for early stopping.\n",
      "\n",
      "Will train until val-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.921904\tval-auc:0.919891\n",
      "[2]\ttrain-auc:0.924052\tval-auc:0.923247\n",
      "[3]\ttrain-auc:0.930314\tval-auc:0.928975\n",
      "[4]\ttrain-auc:0.933408\tval-auc:0.932319\n",
      "[5]\ttrain-auc:0.93707\tval-auc:0.936188\n",
      "[6]\ttrain-auc:0.939046\tval-auc:0.93745\n",
      "[7]\ttrain-auc:0.940209\tval-auc:0.938412\n",
      "[8]\ttrain-auc:0.941683\tval-auc:0.940202\n",
      "[9]\ttrain-auc:0.94309\tval-auc:0.941547\n",
      "[10]\ttrain-auc:0.944024\tval-auc:0.941847\n",
      "[11]\ttrain-auc:0.944903\tval-auc:0.943164\n",
      "[12]\ttrain-auc:0.945512\tval-auc:0.943586\n",
      "[13]\ttrain-auc:0.946775\tval-auc:0.94491\n",
      "[14]\ttrain-auc:0.947603\tval-auc:0.945508\n",
      "[15]\ttrain-auc:0.947978\tval-auc:0.945747\n",
      "[16]\ttrain-auc:0.948387\tval-auc:0.946162\n",
      "[17]\ttrain-auc:0.949227\tval-auc:0.947387\n",
      "[18]\ttrain-auc:0.949438\tval-auc:0.947772\n",
      "[19]\ttrain-auc:0.950643\tval-auc:0.949039\n",
      "[20]\ttrain-auc:0.951542\tval-auc:0.949741\n",
      "[21]\ttrain-auc:0.95225\tval-auc:0.95047\n",
      "[22]\ttrain-auc:0.953035\tval-auc:0.951193\n",
      "[23]\ttrain-auc:0.953824\tval-auc:0.951841\n",
      "[24]\ttrain-auc:0.954373\tval-auc:0.952424\n",
      "[25]\ttrain-auc:0.955104\tval-auc:0.953401\n",
      "[26]\ttrain-auc:0.95605\tval-auc:0.954044\n",
      "[27]\ttrain-auc:0.956557\tval-auc:0.954278\n",
      "[28]\ttrain-auc:0.957278\tval-auc:0.955395\n",
      "[29]\ttrain-auc:0.957869\tval-auc:0.955888\n",
      "[30]\ttrain-auc:0.958125\tval-auc:0.956356\n",
      "[31]\ttrain-auc:0.95848\tval-auc:0.956772\n",
      "[32]\ttrain-auc:0.958858\tval-auc:0.957256\n",
      "[33]\ttrain-auc:0.959057\tval-auc:0.95745\n",
      "[34]\ttrain-auc:0.959401\tval-auc:0.957891\n",
      "[35]\ttrain-auc:0.9601\tval-auc:0.958621\n",
      "[36]\ttrain-auc:0.960675\tval-auc:0.959182\n",
      "[37]\ttrain-auc:0.961312\tval-auc:0.959762\n",
      "[38]\ttrain-auc:0.961996\tval-auc:0.960375\n",
      "[39]\ttrain-auc:0.962399\tval-auc:0.960694\n",
      "[40]\ttrain-auc:0.962565\tval-auc:0.960901\n",
      "[41]\ttrain-auc:0.963028\tval-auc:0.961326\n",
      "[42]\ttrain-auc:0.963414\tval-auc:0.961609\n",
      "[43]\ttrain-auc:0.963907\tval-auc:0.96219\n",
      "[44]\ttrain-auc:0.964403\tval-auc:0.962638\n",
      "[45]\ttrain-auc:0.964642\tval-auc:0.962888\n",
      "[46]\ttrain-auc:0.964741\tval-auc:0.962987\n",
      "[47]\ttrain-auc:0.964951\tval-auc:0.963186\n",
      "[48]\ttrain-auc:0.965181\tval-auc:0.963396\n",
      "[49]\ttrain-auc:0.965727\tval-auc:0.963887\n",
      "[50]\ttrain-auc:0.966138\tval-auc:0.96423\n",
      "[51]\ttrain-auc:0.966715\tval-auc:0.964892\n",
      "[52]\ttrain-auc:0.967157\tval-auc:0.96553\n",
      "[53]\ttrain-auc:0.967403\tval-auc:0.965879\n",
      "[54]\ttrain-auc:0.9678\tval-auc:0.966234\n",
      "[55]\ttrain-auc:0.968257\tval-auc:0.9669\n",
      "[56]\ttrain-auc:0.968631\tval-auc:0.967325\n",
      "[57]\ttrain-auc:0.969025\tval-auc:0.96772\n",
      "[58]\ttrain-auc:0.969437\tval-auc:0.968163\n",
      "[59]\ttrain-auc:0.969763\tval-auc:0.968579\n",
      "[60]\ttrain-auc:0.97013\tval-auc:0.969007\n",
      "[61]\ttrain-auc:0.970453\tval-auc:0.969265\n",
      "[62]\ttrain-auc:0.970737\tval-auc:0.969541\n",
      "[63]\ttrain-auc:0.970872\tval-auc:0.969673\n",
      "[64]\ttrain-auc:0.971193\tval-auc:0.970007\n",
      "[65]\ttrain-auc:0.971465\tval-auc:0.970321\n",
      "[66]\ttrain-auc:0.971697\tval-auc:0.970561\n",
      "[67]\ttrain-auc:0.971895\tval-auc:0.970816\n",
      "[68]\ttrain-auc:0.972321\tval-auc:0.971276\n",
      "[69]\ttrain-auc:0.972475\tval-auc:0.971507\n",
      "[70]\ttrain-auc:0.97271\tval-auc:0.971838\n",
      "[71]\ttrain-auc:0.972989\tval-auc:0.972055\n",
      "[72]\ttrain-auc:0.973219\tval-auc:0.972335\n",
      "[73]\ttrain-auc:0.973507\tval-auc:0.972579\n",
      "[74]\ttrain-auc:0.973729\tval-auc:0.972796\n",
      "[75]\ttrain-auc:0.973958\tval-auc:0.972964\n",
      "[76]\ttrain-auc:0.974247\tval-auc:0.97321\n",
      "[77]\ttrain-auc:0.974376\tval-auc:0.973339\n",
      "[78]\ttrain-auc:0.974477\tval-auc:0.973449\n",
      "[79]\ttrain-auc:0.974635\tval-auc:0.973628\n",
      "[80]\ttrain-auc:0.974731\tval-auc:0.973774\n",
      "[81]\ttrain-auc:0.974918\tval-auc:0.973969\n",
      "[82]\ttrain-auc:0.975013\tval-auc:0.974015\n",
      "[83]\ttrain-auc:0.975224\tval-auc:0.974248\n",
      "[84]\ttrain-auc:0.975505\tval-auc:0.974529\n",
      "[85]\ttrain-auc:0.975722\tval-auc:0.974733\n",
      "[86]\ttrain-auc:0.976049\tval-auc:0.975105\n",
      "[87]\ttrain-auc:0.976266\tval-auc:0.975338\n",
      "[88]\ttrain-auc:0.976481\tval-auc:0.975615\n",
      "[89]\ttrain-auc:0.976667\tval-auc:0.975793\n",
      "[90]\ttrain-auc:0.976835\tval-auc:0.975912\n",
      "[91]\ttrain-auc:0.976949\tval-auc:0.976028\n",
      "[92]\ttrain-auc:0.977042\tval-auc:0.976117\n",
      "[93]\ttrain-auc:0.977239\tval-auc:0.976315\n",
      "[94]\ttrain-auc:0.977394\tval-auc:0.976438\n",
      "[95]\ttrain-auc:0.977508\tval-auc:0.976551\n",
      "[96]\ttrain-auc:0.97779\tval-auc:0.976857\n",
      "[97]\ttrain-auc:0.977888\tval-auc:0.977008\n",
      "[98]\ttrain-auc:0.978059\tval-auc:0.977186\n",
      "[99]\ttrain-auc:0.978152\tval-auc:0.977294\n",
      "[100]\ttrain-auc:0.978269\tval-auc:0.977465\n",
      "[101]\ttrain-auc:0.978447\tval-auc:0.977616\n",
      "[102]\ttrain-auc:0.978665\tval-auc:0.977871\n",
      "[103]\ttrain-auc:0.97877\tval-auc:0.977915\n",
      "[104]\ttrain-auc:0.978911\tval-auc:0.977938\n",
      "[105]\ttrain-auc:0.979073\tval-auc:0.978086\n",
      "[106]\ttrain-auc:0.979175\tval-auc:0.978158\n",
      "[107]\ttrain-auc:0.979357\tval-auc:0.978276\n",
      "[108]\ttrain-auc:0.979421\tval-auc:0.978329\n",
      "[109]\ttrain-auc:0.979587\tval-auc:0.978418\n",
      "[110]\ttrain-auc:0.979705\tval-auc:0.97854\n",
      "[111]\ttrain-auc:0.9798\tval-auc:0.978631\n",
      "[112]\ttrain-auc:0.979903\tval-auc:0.978698\n",
      "[113]\ttrain-auc:0.98002\tval-auc:0.978816\n",
      "[114]\ttrain-auc:0.980125\tval-auc:0.978924\n",
      "[115]\ttrain-auc:0.980231\tval-auc:0.979048\n",
      "[116]\ttrain-auc:0.980258\tval-auc:0.97907\n",
      "[117]\ttrain-auc:0.980396\tval-auc:0.979264\n",
      "[118]\ttrain-auc:0.980487\tval-auc:0.979393\n",
      "[119]\ttrain-auc:0.980644\tval-auc:0.979554\n",
      "[120]\ttrain-auc:0.980779\tval-auc:0.979693\n",
      "[121]\ttrain-auc:0.980951\tval-auc:0.979818\n",
      "[122]\ttrain-auc:0.981056\tval-auc:0.979882\n",
      "[123]\ttrain-auc:0.98115\tval-auc:0.980027\n",
      "[124]\ttrain-auc:0.981288\tval-auc:0.980197\n",
      "[125]\ttrain-auc:0.98144\tval-auc:0.980347\n",
      "[126]\ttrain-auc:0.981523\tval-auc:0.980499\n",
      "[127]\ttrain-auc:0.981634\tval-auc:0.980675\n",
      "[128]\ttrain-auc:0.981747\tval-auc:0.980832\n",
      "[129]\ttrain-auc:0.981861\tval-auc:0.981029\n"
     ]
    }
   ],
   "source": [
    "dtrain2 = xgb.DMatrix(X_train,label=Y_train)\n",
    "dtrain = xgb.DMatrix(X,label=Y)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "eta = 0.9\n",
    "max_depth = 5\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "\n",
    "print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\" : \"gbtree\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": eta,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"subsample\": subsample,\n",
    "    \"colsample_bytree\": colsample_bytree,\n",
    "    \"silent\": 1,\n",
    "    \"seed\": 19960429\n",
    "}\n",
    "\n",
    "watchlist  = [(dtrain,'train'),(dtrain2,'val')]\n",
    "num_round = 300\n",
    "early_stopping_rounds=10\n",
    "bst = xgb.train(params, dtrain, num_round, watchlist, early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = bst.predict(dtest)\n",
    "output = pd.DataFrame({ 'activity_id' : test['activity_id'], 'outcome': ypred })\n",
    "output.head()\n",
    "output.to_csv('output/without_leak.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}